{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler, OrdinalEncoder\n",
    "import random\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# fechas\n",
    "from datetime import datetime\n",
    "\n",
    "# gráficos\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# algoritmos de clasificación\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# algoritmos de regresión\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# métricas\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# hiperparametrización\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TensorFlow y tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from numpy import random\n",
    "random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/Herre/Desktop/TFM/Nuclio_EasyMoney/0_Data/df_preprocessing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nos hemos dado cuenta de que las columnas \"entry_date\" y \"pk_partition\" se han vuelto a convertir en tipo Object\n",
    "df_encoding['entry_date'] = pd.to_datetime(df_encoding['entry_date'], errors='coerce', format='%Y-%m-%d')\n",
    "df_encoding['pk_partition'] = pd.to_datetime(df_encoding['pk_partition'], errors='coerce', format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columnas separadas para año, mes y día\n",
    "df_encoding['entry_date_year'] = df_encoding['entry_date'].dt.year\n",
    "df_encoding['entry_date_month'] = df_encoding['entry_date'].dt.month\n",
    "df_encoding['entry_date_day'] = df_encoding['entry_date'].dt.day\n",
    "df_encoding['entry_date_weekday'] = df_encoding['entry_date'].dt.weekday  # 0=Monday, 6=Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding['pk_partition_year'] = df_encoding['pk_partition'].dt.year\n",
    "df_encoding['pk_partition_month'] = df_encoding['pk_partition'].dt.month\n",
    "df_encoding['pk_partition_day'] = df_encoding['pk_partition'].dt.day\n",
    "df_encoding['pk_partition_weekday'] = df_encoding['pk_partition'].dt.weekday  # 0=Monday, 6=Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como ya hemos creado una columna para años, mes, dia y día de la semana. Podemos elimianr la columna original\n",
    "df_encoding.drop(columns=['entry_date'], inplace=True)\n",
    "df_encoding.drop(columns=['pk_partition'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columnas_OHE = [\"entry_channel\", \"country_id\", \"gender\", \"deceased\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las variables categóricas en variables dummy\n",
    "df_encoding = pd.get_dummies(data=df_encoding, columns=Columnas_OHE, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario para el mapeo de valores\n",
    "ordinal_mapping = {\n",
    "    'Unknown': 0,\n",
    "    '03 - UNIVERSITARIO': 1,\n",
    "    '02 - PARTICULARES': 2,\n",
    "    '01 - TOP': 3\n",
    "}\n",
    "\n",
    "# Aplicar el mapeo a la columna 'segment'\n",
    "df_encoding['segment'] = df_encoding['segment'].map(ordinal_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borrar columnas duales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las columnas especificadas\n",
    "df_encoding.drop(columns=[\"gender_H\", \"deceased_N\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una vez hemos hecho todo esto ya no tenemos columnas categóricas en todo el dataframe, solo nos quedan las fechas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportamos el archivo para pasar a la segmentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados\n",
    "df_encoding.to_csv('df_encoding.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
