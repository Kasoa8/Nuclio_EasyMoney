{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler, OrdinalEncoder\n",
    "import random\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# fechas\n",
    "from datetime import datetime\n",
    "\n",
    "# gráficos\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# algoritmos de clasificación\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# algoritmos de regresión\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# métricas\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# hiperparametrización\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TensorFlow y tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from numpy import random\n",
    "random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar pandas para mostrar más valores\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/Herre/Desktop/commercial_activity_df.csv\"\n",
    "file_path_2 = \"C:/Users/Herre/Desktop/products_df.csv\"\n",
    "file_path_3 = \"C:/Users\\Herre\\Desktop\\sociodemographic_df.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comercial_activity = pd.read_csv(file_path)\n",
    "df_products = pd.read_csv(file_path_2)\n",
    "df_socialdemographic = pd.read_csv(file_path_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Análisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA df_comercial_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5962924 entries, 0 to 5962923\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Unnamed: 0       int64  \n",
      " 1   pk_cid           int64  \n",
      " 2   pk_partition     object \n",
      " 3   entry_date       object \n",
      " 4   entry_channel    object \n",
      " 5   active_customer  float64\n",
      " 6   segment          object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 318.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_comercial_activity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_channel</th>\n",
       "      <th>active_customer</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1375586</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>KHL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>02 - PARTICULARES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1050611</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>KHE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1050612</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>KHE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1050613</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>KHD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1050614</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>KHE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   pk_cid pk_partition  entry_date entry_channel  \\\n",
       "0           0  1375586   2018-01-28  2018-01-12           KHL   \n",
       "1           1  1050611   2018-01-28  2015-08-10           KHE   \n",
       "2           2  1050612   2018-01-28  2015-08-10           KHE   \n",
       "3           3  1050613   2018-01-28  2015-08-10           KHD   \n",
       "4           4  1050614   2018-01-28  2015-08-10           KHE   \n",
       "\n",
       "   active_customer             segment  \n",
       "0              1.0   02 - PARTICULARES  \n",
       "1              0.0  03 - UNIVERSITARIO  \n",
       "2              0.0  03 - UNIVERSITARIO  \n",
       "3              0.0  03 - UNIVERSITARIO  \n",
       "4              1.0  03 - UNIVERSITARIO  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comercial_activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_categoricas = df_comercial_activity.select_dtypes(include=['object']).columns.tolist()\n",
    "columnas_numericas = df_comercial_activity.select_dtypes(include=['int', 'float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in pk_partition: ['2018-01-28' '2018-02-28' '2018-03-28' '2018-04-28' '2018-05-28'\n",
      " '2018-06-28' '2018-07-28' '2018-08-28' '2018-09-28' '2018-10-28'\n",
      " '2018-11-28' '2018-12-28' '2019-01-28' '2019-02-28' '2019-03-28'\n",
      " '2019-04-28' '2019-05-28']\n",
      "Unique values in entry_date: ['2018-01-12' '2015-08-10' '2015-08-16' '2015-08-14' '2015-08-15'\n",
      " '2015-08-20' '2015-10-10' '2015-08-17' '2017-07-09' '2017-10-28'\n",
      " '2015-12-28' '2015-08-13' '2015-08-31' '2015-08-09' '2015-09-05'\n",
      " '2017-09-28' '2015-09-20' '2015-09-04' '2015-09-24' '2015-09-06'\n",
      " '2015-09-03' '2015-09-12' '2015-09-17' '2016-01-21' '2015-09-07'\n",
      " '2015-09-27' '2017-09-19' '2017-08-28' '2016-03-20' '2015-10-09'\n",
      " '2015-09-11' '2015-09-10' '2016-07-26' '2016-07-11' '2016-04-03'\n",
      " '2015-08-30' '2017-12-18' '2016-02-21' '2015-08-22' '2015-08-21'\n",
      " '2015-08-29' '2015-10-03' '2015-08-23' '2017-01-28' '2015-08-27'\n",
      " '2016-12-21' '2015-08-24' '2015-12-20' '2015-08-28' '2015-11-15'\n",
      " '2015-10-11' '2017-08-04' '2016-05-08' '2015-08-26' '2017-03-05'\n",
      " '2015-08-06' '2015-08-07' '2017-12-10' '2016-11-20' '2016-04-12'\n",
      " '2015-08-03' '2016-10-22' '2015-08-08' '2015-11-10' '2015-09-25'\n",
      " '2015-09-21' '2016-10-24' '2017-01-22' '2015-10-17' '2017-12-05'\n",
      " '2017-11-27' '2015-10-22' '2017-06-03' '2017-01-03' '2015-09-26'\n",
      " '2015-10-02' '2016-10-04' '2015-10-29' '2017-06-12' '2015-10-01'\n",
      " '2017-01-27' '2015-10-31' '2015-09-13' '2015-09-14' '2015-09-18'\n",
      " '2016-05-28' '2017-04-25' '2017-09-10' '2017-02-17' '2015-09-19'\n",
      " '2015-10-16' '2015-10-05' '2016-10-08' '2016-06-18' '2016-02-04'\n",
      " '2017-01-31' '2015-10-15' '2016-03-26' '2015-09-16' '2016-01-23'\n",
      " '2016-01-31' '2017-01-18' '2015-07-19' '2015-07-18' '2015-07-17'\n",
      " '2016-09-19' '2015-07-16' '2015-12-04' '2017-11-24' '2015-07-13'\n",
      " '2016-07-10' '2015-07-12' '2015-07-27' '2015-07-23' '2016-11-26'\n",
      " '2016-04-01' '2015-07-24' '2015-07-25' '2015-07-20' '2016-04-10'\n",
      " '2017-05-28' '2016-01-08' '2017-04-04' '2016-12-05' '2015-05-18'\n",
      " '2015-11-12' '2017-12-09' '2015-05-17' '2015-06-21' '2016-11-22'\n",
      " '2015-05-21' '2016-10-05' '2015-06-27' '2015-09-28' '2015-06-06'\n",
      " '2015-05-20' '2015-05-14' '2015-05-15' '2015-05-11' '2015-05-12'\n",
      " '2015-05-13' '2015-05-16' '2017-11-20' '2015-06-05' '2015-10-25'\n",
      " '2016-10-25' '2015-06-19' '2015-05-22' '2015-05-29' '2016-09-12'\n",
      " '2015-05-30' '2016-03-22' '2015-05-31' '2015-05-28' '2016-04-25'\n",
      " '2015-06-01' '2015-06-22' '2015-05-23' '2015-05-24' '2016-11-21'\n",
      " '2015-05-25' '2017-08-14' '2015-04-27' '2015-04-28' '2015-04-30'\n",
      " '2015-04-26' '2016-10-29' '2017-08-13' '2015-05-01' '2015-05-02'\n",
      " '2015-04-24' '2015-04-23' '2015-04-25' '2015-07-06' '2015-06-04'\n",
      " '2017-05-05' '2015-08-01' '2015-05-09' '2015-11-29' '2015-05-08'\n",
      " '2017-07-11' '2016-05-06' '2015-05-10' '2017-12-23' '2017-10-23'\n",
      " '2015-05-04' '2015-05-03' '2015-05-05' '2017-05-16' '2017-09-29'\n",
      " '2015-05-07' '2015-06-07' '2016-04-11' '2017-08-25' '2016-06-12'\n",
      " '2015-07-02' '2015-07-03' '2015-06-29' '2015-07-01' '2015-07-04'\n",
      " '2016-01-03' '2015-06-26' '2015-06-28' '2015-07-10' '2017-10-13'\n",
      " '2015-07-11' '2015-07-09' '2016-01-09' '2017-10-21' '2015-07-05'\n",
      " '2016-07-20' '2018-01-26' '2015-07-07' '2015-07-08' '2015-06-08'\n",
      " '2015-06-10' '2015-06-11' '2016-07-03' '2017-09-03' '2017-10-24'\n",
      " '2015-06-12' '2015-06-13' '2016-12-20' '2016-04-15' '2017-05-14'\n",
      " '2015-10-26' '2017-03-18' '2017-01-14' '2015-07-31' '2015-11-05'\n",
      " '2015-06-03' '2016-03-19' '2015-12-27' '2015-06-14' '2015-09-23'\n",
      " '2016-12-03' '2016-10-14' '2015-06-25' '2015-06-20' '2016-10-07'\n",
      " '2015-06-15' '2017-07-08' '2015-06-17' '2015-06-18' '2016-08-06'\n",
      " '2018-01-06' '2017-09-12' '2017-03-28' '2015-11-16' '2015-07-30'\n",
      " '2016-01-24' '2016-11-27' '2015-08-02' '2017-05-15' '2015-11-21'\n",
      " '2016-03-25' '2015-07-26' '2015-07-28' '2015-07-29' '2016-11-07'\n",
      " '2015-12-03' '2015-11-26' '2016-04-16' '2015-11-30' '2015-11-23'\n",
      " '2015-11-24' '2015-11-27' '2015-11-28' '2017-04-16' '2017-12-14'\n",
      " '2017-09-02' '2018-01-08' '2015-11-20' '2015-11-22' '2016-06-05'\n",
      " '2015-12-25' '2016-07-19' '2016-08-14' '2016-05-23' '2016-07-22'\n",
      " '2016-06-11' '2015-12-05' '2016-10-11' '2015-12-07' '2017-02-18'\n",
      " '2017-06-04' '2016-09-04' '2016-08-19' '2016-01-10' '2015-12-19'\n",
      " '2015-12-10' '2015-12-01' '2015-12-02' '2015-12-21' '2016-07-16'\n",
      " '2017-04-17' '2015-11-11' '2015-11-13' '2017-08-06' '2016-02-16'\n",
      " '2016-01-17' '2016-11-25' '2016-03-08' '2015-11-09' '2015-11-07'\n",
      " '2015-11-06' '2015-11-08' '2016-12-04' '2017-06-14' '2016-12-14'\n",
      " '2015-11-19' '2015-11-17' '2015-11-18' '2017-12-22' '2017-11-03'\n",
      " '2015-12-14' '2016-11-06' '2016-08-09' '2016-08-02' '2015-11-14'\n",
      " '2017-01-20' '2016-04-29' '2016-05-13' '2016-03-04' '2016-03-05'\n",
      " '2016-03-11' '2016-03-01' '2016-03-02' '2016-03-03' '2016-03-06'\n",
      " '2016-03-07' '2017-10-09' '2017-06-26' '2016-02-26' '2017-03-02'\n",
      " '2016-02-25' '2016-10-10' '2017-05-06' '2017-06-02' '2016-05-24'\n",
      " '2016-02-28' '2016-02-27' '2016-05-07' '2017-09-17' '2017-06-30'\n",
      " '2016-04-02' '2016-03-18' '2016-05-10' '2016-03-15' '2016-03-14'\n",
      " '2017-06-25' '2016-03-16' '2017-09-16' '2017-11-06' '2016-03-21'\n",
      " '2016-07-18' '2018-01-19' '2017-09-22' '2016-12-30' '2017-11-25'\n",
      " '2016-03-13' '2016-03-12' '2016-08-10' '2016-05-31' '2017-01-21'\n",
      " '2017-02-10' '2016-02-22' '2016-02-06' '2016-02-07' '2016-02-05'\n",
      " '2016-02-11' '2017-10-31' '2016-02-09' '2016-02-08' '2016-10-15'\n",
      " '2017-10-10' '2016-02-01' '2016-10-28' '2016-01-30' '2017-06-27'\n",
      " '2017-11-13' '2016-11-18' '2016-02-02' '2016-12-09' '2016-02-19'\n",
      " '2016-06-03' '2016-09-11' '2016-02-20' '2016-02-18' '2017-11-04'\n",
      " '2016-04-22' '2016-02-12' '2017-08-12' '2016-02-13' '2016-02-15'\n",
      " '2016-09-25' '2016-02-14' '2016-03-27' '2016-02-17' '2017-01-02'\n",
      " '2016-06-25' '2016-04-23' '2016-04-19' '2016-04-21' '2017-02-28'\n",
      " '2016-04-24' '2016-04-26' '2016-04-30' '2016-06-26' '2016-05-02'\n",
      " '2016-08-28' '2016-04-18' '2016-11-28' '2016-04-14' '2016-05-30'\n",
      " '2016-04-17' '2017-05-20' '2017-10-01' '2017-09-08' '2016-05-04'\n",
      " '2016-05-03' '2017-05-27' '2015-12-31' '2017-02-19' '2016-07-24'\n",
      " '2016-08-08' '2017-11-11' '2016-06-24' '2017-07-21' '2016-09-03'\n",
      " '2016-05-01' '2016-05-16' '2016-12-17' '2017-10-06' '2016-06-17'\n",
      " '2016-05-09' '2016-03-28' '2016-05-27' '2016-03-31' '2016-04-04'\n",
      " '2016-07-01' '2017-02-26' '2016-07-17' '2016-10-21' '2016-10-20'\n",
      " '2016-07-04' '2016-04-09' '2016-08-16' '2016-04-08' '2017-07-22'\n",
      " '2017-02-09' '2017-11-26' '2016-10-30' '2016-06-10' '2016-07-07'\n",
      " '2016-04-05' '2016-08-30' '2016-04-06' '2015-12-17' '2015-12-13'\n",
      " '2017-06-09' '2015-12-26' '2015-12-24' '2017-01-25' '2015-12-18'\n",
      " '2016-11-12' '2017-03-19' '2016-11-15' '2015-12-12' '2017-10-02'\n",
      " '2015-12-11' '2017-04-14' '2016-11-29' '2016-10-02' '2016-01-15'\n",
      " '2016-01-16' '2016-01-14' '2016-01-18' '2016-10-09' '2016-01-28'\n",
      " '2017-05-08' '2017-01-13' '2016-12-27' '2016-05-15' '2016-06-16'\n",
      " '2016-01-13' '2016-01-12' '2016-01-11' '2016-08-23' '2016-01-29'\n",
      " '2016-01-26' '2016-01-25' '2017-11-14' '2016-05-14' '2017-11-05'\n",
      " '2016-01-22' '2016-01-19' '2016-01-02' '2016-01-04' '2017-01-04'\n",
      " '2016-01-01' '2015-12-30' '2015-12-29' '2017-05-19' '2017-07-18'\n",
      " '2017-02-11' '2016-01-07' '2016-01-06' '2015-10-08' '2015-10-23'\n",
      " '2016-10-23' '2017-11-21' '2015-10-06' '2015-10-24' '2015-10-13'\n",
      " '2015-10-14' '2016-02-03' '2016-05-21' '2017-02-24' '2015-10-04'\n",
      " '2015-10-18' '2017-10-14' '2015-10-30' '2016-10-13' '2016-09-05'\n",
      " '2015-11-02' '2015-10-27' '2017-08-22' '2017-12-16' '2017-08-18'\n",
      " '2017-07-02' '2017-03-13' '2015-11-03' '2017-08-05' '2015-10-19'\n",
      " '2015-10-20' '2017-08-29' '2015-01-17' '2017-05-26' '2018-01-09'\n",
      " '2016-09-28' '2017-12-03' '2017-10-08' '2017-06-17' '2016-08-13'\n",
      " '2016-12-12' '2016-06-20' '2016-07-05' '2016-07-25' '2017-01-08'\n",
      " '2016-07-14' '2017-02-03' '2016-11-14' '2015-06-16' '2017-07-03'\n",
      " '2015-04-12' '2016-07-15' '2017-07-12' '2017-07-04' '2017-03-12'\n",
      " '2016-12-26' '2016-11-05' '2017-02-14' '2016-07-02' '2015-01-02'\n",
      " '2017-01-07' '2016-08-21' '2016-11-08' '2016-09-27' '2016-05-19'\n",
      " '2015-03-07' '2017-06-18' '2017-08-03' '2015-03-15' '2017-10-15'\n",
      " '2016-09-10' '2018-01-02' '2017-06-20' '2017-09-26' '2015-02-12'\n",
      " '2016-09-18' '2015-03-08' '2017-09-30' '2015-03-21' '2016-09-09'\n",
      " '2017-11-12' '2017-06-05' '2017-02-12' '2015-03-23' '2016-10-19'\n",
      " '2015-03-09' '2017-06-16' '2016-08-29' '2016-09-20' '2015-04-10'\n",
      " '2016-08-27' '2018-01-05' '2015-02-21' '2017-06-13' '2017-10-20'\n",
      " '2017-07-28' '2017-02-05' '2015-01-18' '2016-09-17' '2017-04-24'\n",
      " '2015-02-09' '2017-02-20' '2017-07-10' '2017-08-07' '2017-08-21'\n",
      " '2017-04-29' '2018-01-16' '2017-04-30' '2017-03-11' '2017-11-07'\n",
      " '2016-12-23' '2017-03-17' '2017-06-28' '2016-06-13' '2015-01-23'\n",
      " '2017-03-21' '2017-04-08' '2017-11-19' '2015-02-14' '2015-03-20'\n",
      " '2015-01-03' '2015-02-01' '2017-02-13' '2018-01-15' '2017-12-24'\n",
      " '2015-04-03' '2017-05-12' '2017-05-21' '2017-10-29' '2017-12-15'\n",
      " '2016-05-17' '2015-04-06' '2017-12-04' '2016-09-06' '2015-03-14'\n",
      " '2017-06-10' '2016-09-26' '2017-04-07' '2016-08-24' '2018-01-03'\n",
      " '2016-07-08' '2017-01-16' '2015-01-16' '2015-01-11' '2015-01-13'\n",
      " '2015-04-02' '2016-06-19' '2017-06-23' '2016-07-31' '2017-01-11'\n",
      " '2016-07-30' '2015-03-05' '2017-05-09' '2016-12-28' '2017-11-02'\n",
      " '2015-04-09' '2017-10-07' '2015-02-20' '2017-12-29' '2015-04-04'\n",
      " '2015-02-16' '2015-04-13' '2015-02-17' '2015-04-05' '2015-02-15'\n",
      " '2017-09-04' '2016-10-16' '2017-01-09' '2017-02-23' '2015-02-18'\n",
      " '2015-02-19' '2015-03-29' '2015-04-17' '2015-02-08' '2015-02-10'\n",
      " '2015-02-07' '2015-02-06' '2015-02-13' '2015-03-01' '2015-02-28'\n",
      " '2017-01-15' '2015-02-27' '2015-04-16' '2015-02-29' '2015-02-22'\n",
      " '2015-02-23' '2015-02-24' '2015-02-26' '2015-02-25' '2017-02-07'\n",
      " '2015-01-19' '2015-01-24' '2015-01-20' '2015-01-12' '2015-02-02'\n",
      " '2015-01-10' '2015-01-09' '2015-01-31' '2015-01-14' '2015-03-06'\n",
      " '2015-03-27' '2015-01-30' '2016-11-19' '2015-02-03' '2015-01-25'\n",
      " '2015-01-26' '2015-01-27' '2017-01-23' '2015-01-29' '2015-01-28'\n",
      " '2015-03-30' '2016-05-29' '2016-04-20' '2015-03-28' '2015-03-26'\n",
      " '2015-04-18' '2015-04-19' '2015-04-20' '2016-10-17' '2015-04-11'\n",
      " '2017-02-25' '2016-12-01' '2017-08-19' '2015-03-10' '2015-03-12'\n",
      " '2015-03-13' '2015-03-02' '2015-03-04' '2015-03-22' '2017-06-24'\n",
      " '2016-08-20' '2015-11-04' '2015-03-25' '2017-06-06' '2015-03-16'\n",
      " '2017-12-12' '2017-03-25' '2015-03-19' '2015-03-17' '2017-02-06'\n",
      " '2017-01-29' '2017-01-01' '2017-03-14' '2015-01-05' '2015-01-08'\n",
      " '2015-01-04' '2017-03-27' '2017-07-14' '2016-07-09' '2015-04-08'\n",
      " '2017-04-09' '2016-04-27' '2017-09-24' '2017-08-20' '2017-08-16'\n",
      " '2017-12-19' '2017-08-26' '2017-08-27' '2017-09-05' '2017-08-23'\n",
      " '2017-09-11' '2017-08-08' '2017-08-11' '2017-09-27' '2017-09-01'\n",
      " '2017-08-01' '2017-07-31' '2017-07-30' '2017-12-11' '2017-08-02'\n",
      " '2017-10-03' '2017-09-15' '2017-09-13' '2017-09-18' '2017-10-17'\n",
      " '2017-10-04' '2017-12-26' '2018-01-07' '2018-01-10' '2017-10-12'\n",
      " '2017-08-30' '2017-08-31' '2017-10-16' '2017-09-09' '2017-09-25'\n",
      " '2017-11-28' '2017-11-17' '2018-01-13' '2017-07-01' '2018-01-27'\n",
      " '2018-01-14' '2017-07-07' '2017-07-15' '2017-07-24' '2017-06-19'\n",
      " '2017-07-23' '2017-12-31' '2017-06-21' '2017-10-27' '2017-07-17'\n",
      " '2017-07-19' '2017-07-13' '2017-07-16' '2017-05-29' '2017-05-07'\n",
      " '2017-05-02' '2017-04-28' '2017-12-30' '2017-05-01' '2017-05-23'\n",
      " '2017-05-13' '2017-04-15' '2017-04-20' '2017-04-21' '2017-04-10'\n",
      " '2017-04-11' '2018-01-22' '2017-04-23' '2017-11-18' '2017-05-22'\n",
      " '2017-04-22' '2017-12-01' '2017-05-30' '2017-06-01' '2017-11-29'\n",
      " '2017-11-08' '2017-06-11' '2017-10-30' '2017-08-09' '2017-07-29'\n",
      " '2017-07-25' '2017-07-26' '2017-11-10' '2017-12-17' '2017-11-15'\n",
      " '2017-11-16' '2017-12-02' '2017-10-25' '2017-12-20' '2017-12-27'\n",
      " '2018-01-21' '2017-12-08' '2018-01-20' '2018-01-23' '2018-01-24'\n",
      " '2018-01-28' '2018-01-29' '2018-01-30' '2018-01-01' '2017-11-22'\n",
      " '2017-11-23' '2017-09-23' '2017-10-22' '2016-08-26' '2016-10-01'\n",
      " '2016-09-02' '2016-09-01' '2016-09-24' '2016-08-25' '2016-09-23'\n",
      " '2016-08-22' '2017-04-03' '2017-12-13' '2016-09-13' '2016-08-12'\n",
      " '2016-12-10' '2016-09-30' '2016-10-03' '2016-11-11' '2016-09-16'\n",
      " '2017-04-26' '2018-01-25' '2016-07-23' '2016-06-07' '2016-06-06'\n",
      " '2016-06-28' '2016-06-21' '2016-06-04' '2016-07-28' '2016-06-23'\n",
      " '2016-06-14' '2016-05-20' '2016-05-22' '2016-05-26' '2016-07-12'\n",
      " '2016-09-21' '2017-03-31' '2016-11-04' '2016-06-27' '2016-06-30'\n",
      " '2016-08-03' '2016-08-05' '2016-08-07' '2016-08-04' '2016-07-29'\n",
      " '2016-08-01' '2016-07-27' '2017-11-09' '2017-01-17' '2016-11-24'\n",
      " '2016-11-23' '2016-12-11' '2017-03-03' '2017-01-10' '2016-12-19'\n",
      " '2016-12-06' '2016-12-16' '2017-06-08' '2016-12-13' '2016-12-02'\n",
      " '2016-12-08' '2016-11-30' '2017-01-06' '2016-11-13' '2016-12-18'\n",
      " '2016-12-31' '2017-02-27' '2017-03-06' '2017-03-20' '2017-03-10'\n",
      " '2017-03-07' '2017-04-01' '2017-03-08' '2017-03-09' '2017-03-04'\n",
      " '2017-03-24' '2017-02-15' '2017-02-16' '2017-02-21' '2017-06-22'\n",
      " '2017-04-02' '2017-09-06' '2017-03-26' '2017-04-13' '2017-06-15'\n",
      " '2017-01-30' '2016-12-22' '2016-12-24' '2017-01-24' '2017-01-26'\n",
      " '2017-02-04' '2017-05-24' '2016-10-31' '2016-10-18' '2016-11-10'\n",
      " '2016-11-02' '2016-11-03' '2016-11-16' '2017-08-17' '2016-09-08'\n",
      " '2016-05-12' '2015-05-26' '2015-09-15' '2016-05-18' '2015-12-08'\n",
      " '2017-10-05' '2017-05-04' '2017-04-06' '2017-06-07' '2017-03-29'\n",
      " '2016-01-05' '2018-01-04' '2017-04-12' '2017-10-26' '2016-02-24'\n",
      " '2016-05-05' '2015-12-15' '2017-09-20' '2015-01-01' '2016-03-23'\n",
      " '2016-06-08' '2017-01-05' '2015-10-12' '2017-02-02' '2015-02-04'\n",
      " '2016-02-10' '2017-12-21' '2016-03-10' '2015-02-05' '2016-09-22'\n",
      " '2018-02-09' '2018-02-10' '2018-02-13' '2018-02-12' '2018-02-25'\n",
      " '2018-02-02' '2018-02-04' '2018-02-16' '2018-02-11' '2018-02-05'\n",
      " '2018-02-06' '2018-02-23' '2018-02-22' '2018-02-24' '2018-02-03'\n",
      " '2018-02-20' '2018-02-18' '2018-02-27' '2018-01-31' '2018-02-17'\n",
      " '2018-02-01' '2018-02-19' '2018-02-07' '2018-02-26' '2018-02-14'\n",
      " '2018-03-03' '2018-03-18' '2018-03-19' '2018-03-05' '2018-02-28'\n",
      " '2018-03-02' '2018-03-24' '2018-03-16' '2018-03-17' '2018-03-12'\n",
      " '2018-03-13' '2018-03-23' '2018-03-09' '2018-03-04' '2018-03-06'\n",
      " '2018-03-20' '2018-03-27' '2018-03-30' '2018-03-10' '2018-03-26'\n",
      " '2018-03-15' '2018-03-25' '2018-03-11' '2018-03-14' '2018-03-01'\n",
      " '2018-03-31' '2018-02-21' '2015-07-15' '2018-03-28' '2018-04-29'\n",
      " '2018-04-02' '2018-04-15' '2018-03-29' '2018-04-06' '2018-04-08'\n",
      " '2018-04-16' '2018-04-07' '2018-04-23' '2018-04-20' '2018-04-13'\n",
      " '2018-04-10' '2018-04-14' '2018-04-27' '2018-04-22' '2018-04-30'\n",
      " '2018-04-01' '2018-03-21' '2018-04-09' '2018-04-04' '2018-04-17'\n",
      " '2018-04-03' '2018-04-12' '2018-04-05' '2018-04-25' '2018-04-28'\n",
      " '2018-04-21' '2018-04-19' '2018-04-18' '2018-04-24' '2018-04-26'\n",
      " '2017-12-06' '2018-03-08' '2018-05-27' '2018-05-11' '2018-05-13'\n",
      " '2018-05-26' '2018-05-18' '2018-05-07' '2018-05-08' '2018-05-21'\n",
      " '2018-05-01' '2018-05-06' '2018-05-22' '2018-05-04' '2018-05-20'\n",
      " '2018-05-15' '2018-05-14' '2018-05-12' '2018-05-05' '2018-05-16'\n",
      " '2018-05-17' '2018-05-19' '2018-05-25' '2018-05-23' '2018-05-28'\n",
      " '2018-05-29' '2018-05-02' '2018-05-03' '2018-05-09' '2018-05-10'\n",
      " '2018-05-24' '2018-06-15' '2018-06-16' '2018-06-09' '2018-06-22'\n",
      " '2018-06-01' '2018-06-17' '2018-06-18' '2018-06-21' '2018-06-29'\n",
      " '2018-06-05' '2018-06-02' '2018-06-23' '2018-06-03' '2018-06-04'\n",
      " '2018-06-24' '2018-06-26' '2018-06-12' '2018-06-13' '2018-06-14'\n",
      " '2018-06-11' '2018-06-19' '2018-06-08' '2018-06-10' '2018-06-27'\n",
      " '2018-06-28' '2018-06-30' '2018-06-25' '2018-06-20' '2018-06-07'\n",
      " '2018-05-30' '2018-06-06' '2016-05-25' '2018-07-13' '2015-08-19'\n",
      " '2018-07-15' '2018-07-16' '2018-07-24' '2018-07-22' '2018-07-03'\n",
      " '2018-07-21' '2016-06-15' '2018-07-01' '2018-07-27' '2018-07-31'\n",
      " '2018-07-23' '2018-07-28' '2015-04-29' '2018-07-08' '2018-07-29'\n",
      " '2018-07-11' '2018-07-07' '2018-07-17' '2016-03-09' '2017-06-29'\n",
      " '2018-07-20' '2018-07-26' '2018-07-30' '2018-07-14' '2017-11-30'\n",
      " '2018-07-09' '2018-07-02' '2018-07-10' '2018-07-25' '2017-03-30'\n",
      " '2018-07-12' '2015-07-14' '2018-07-06' '2017-04-05' '2017-04-27'\n",
      " '2017-05-11' '2016-08-17' '2016-05-11' '2016-01-20' '2015-09-30'\n",
      " '2017-08-10' '2016-06-09' '2017-12-25' '2016-10-12' '2016-09-07'\n",
      " '2015-04-01' '2017-09-07' '2015-08-11' '2015-04-21' '2015-07-21'\n",
      " '2015-06-02' '2015-06-09' '2018-05-31' '2016-11-01' '2017-03-16'\n",
      " '2018-07-05' '2018-07-04' '2018-07-18' '2018-07-19' '2018-08-04'\n",
      " '2018-08-03' '2018-08-15' '2018-08-07' '2018-08-10' '2018-08-11'\n",
      " '2018-08-17' '2018-08-27' '2018-08-31' '2018-08-26' '2018-08-12'\n",
      " '2018-08-25' '2018-08-18' '2018-08-21' '2018-08-20' '2018-08-30'\n",
      " '2018-08-19' '2018-08-05' '2018-08-28' '2018-08-08' '2018-08-06'\n",
      " '2018-08-24' '2018-08-14' '2018-08-01' '2018-08-13' '2018-08-09'\n",
      " '2018-08-29' '2018-08-16' '2018-08-23' '2018-08-22' '2018-08-02'\n",
      " '2018-09-03' '2018-09-17' '2018-09-21' '2018-09-23' '2018-09-09'\n",
      " '2018-09-08' '2018-09-02' '2018-09-15' '2018-09-22' '2018-09-28'\n",
      " '2018-09-07' '2018-09-10' '2018-09-19' '2018-09-16' '2018-09-11'\n",
      " '2018-09-25' '2018-09-29' '2018-09-18' '2018-09-30' '2018-09-14'\n",
      " '2018-09-27' '2018-09-01' '2018-09-24' '2018-09-05' '2018-09-13'\n",
      " '2018-09-26' '2018-09-20' '2018-09-12' '2018-09-04' '2018-09-06'\n",
      " '2018-10-28' '2018-10-07' '2018-10-27' '2018-10-16' '2018-10-14'\n",
      " '2018-10-19' '2018-10-13' '2018-10-09' '2018-10-21' '2018-10-23'\n",
      " '2018-10-01' '2018-10-17' '2018-10-26' '2018-10-12' '2018-10-08'\n",
      " '2018-10-06' '2018-10-20' '2018-10-29' '2018-10-10' '2018-10-05'\n",
      " '2018-10-18' '2018-10-15' '2018-10-11' '2018-10-02' '2018-10-03'\n",
      " '2018-10-30' '2018-10-04' '2018-10-22' '2018-10-25' '2018-10-24'\n",
      " '2018-11-25' '2018-10-31' '2018-11-11' '2018-11-30' '2018-11-04'\n",
      " '2018-11-10' '2018-11-23' '2018-11-27' '2018-11-18' '2018-11-26'\n",
      " '2018-11-15' '2018-11-13' '2018-11-12' '2018-11-06' '2018-11-05'\n",
      " '2018-11-16' '2018-11-02' '2018-11-19' '2018-11-17' '2018-11-24'\n",
      " '2018-11-07' '2018-11-14' '2018-11-21' '2018-11-20' '2018-11-08'\n",
      " '2018-11-03' '2018-11-09' '2018-11-29' '2018-11-01' '2018-11-28'\n",
      " '2018-11-22' '2018-12-04' '2018-12-14' '2018-12-29' '2018-12-23'\n",
      " '2018-12-30' '2018-12-11' '2018-12-05' '2018-12-17' '2018-12-10'\n",
      " '2018-12-22' '2018-12-02' '2018-12-09' '2018-12-31' '2018-12-28'\n",
      " '2018-12-07' '2018-12-25' '2018-12-18' '2018-12-16' '2018-12-08'\n",
      " '2018-12-27' '2018-12-24' '2018-12-01' '2018-12-20' '2018-12-21'\n",
      " '2018-12-15' '2018-12-03' '2018-12-13' '2018-12-26' '2018-12-19'\n",
      " '2018-12-06' '2018-12-12' '2019-01-04' '2019-01-07' '2019-01-25'\n",
      " '2019-01-20' '2019-01-18' '2019-01-05' '2019-01-12' '2019-01-13'\n",
      " '2019-01-11' '2019-01-14' '2019-01-26' '2019-01-06' '2019-01-22'\n",
      " '2019-01-28' '2019-01-23' '2019-01-17' '2019-01-10' '2019-01-15'\n",
      " '2019-01-29' '2019-01-21' '2019-01-24' '2019-01-09' '2019-01-08'\n",
      " '2019-01-02' '2019-01-19' '2019-01-27' '2019-01-16' '2019-01-01'\n",
      " '2019-01-03' '2019-02-02' '2019-01-31' '2019-02-26' '2019-02-04'\n",
      " '2019-02-05' '2019-02-29' '2019-02-13' '2019-02-22' '2019-02-11'\n",
      " '2019-02-23' '2019-02-16' '2019-02-24' '2019-02-06' '2019-02-25'\n",
      " '2019-02-14' '2019-02-01' '2019-02-19' '2019-02-08' '2019-02-21'\n",
      " '2019-02-17' '2019-02-15' '2019-02-28' '2019-02-12' '2019-02-09'\n",
      " '2019-02-03' '2019-02-10' '2019-02-18' '2019-02-27' '2019-02-20'\n",
      " '2019-02-07' '2019-01-30' '2019-03-28' '2019-03-29' '2019-03-03'\n",
      " '2019-03-22' '2019-03-01' '2019-03-31' '2019-03-11' '2019-03-02'\n",
      " '2019-03-21' '2019-03-23' '2019-03-10' '2019-03-15' '2019-03-14'\n",
      " '2019-03-09' '2019-03-18' '2019-03-13' '2019-03-05' '2019-03-17'\n",
      " '2019-03-08' '2019-03-07' '2019-03-04' '2019-03-30' '2019-03-24'\n",
      " '2019-03-16' '2019-03-20' '2019-03-19' '2019-03-25' '2019-03-27'\n",
      " '2019-03-26' '2019-03-06' '2019-03-12' '2019-04-13' '2019-04-01'\n",
      " '2019-04-19' '2019-04-18' '2019-04-02' '2019-04-26' '2019-04-11'\n",
      " '2019-04-07' '2019-04-14' '2019-04-10' '2019-04-06' '2019-04-25'\n",
      " '2019-04-12' '2019-04-08' '2019-04-20' '2019-04-04' '2019-04-29'\n",
      " '2019-04-27' '2019-04-15' '2019-04-28' '2019-04-05' '2019-04-23'\n",
      " '2019-04-21' '2019-04-03' '2019-04-09' '2019-04-22' '2019-04-24'\n",
      " '2019-04-17' '2019-04-16' '2019-05-12' '2019-05-06' '2019-05-05'\n",
      " '2019-05-21' '2019-05-17' '2019-05-26' '2019-05-03' '2019-05-07'\n",
      " '2019-05-31' '2019-05-20' '2019-05-08' '2019-05-18' '2019-05-23'\n",
      " '2019-05-28' '2019-05-30' '2019-05-04' '2019-05-19' '2019-05-13'\n",
      " '2019-05-09' '2019-05-24' '2019-05-29' '2019-05-16' '2019-05-10'\n",
      " '2019-05-02' '2019-05-14' '2019-05-22' '2019-05-11' '2019-04-30'\n",
      " '2019-05-27' '2019-05-25' '2019-05-01' '2019-05-15']\n",
      "Unique values in entry_channel: ['KHL' 'KHE' 'KHD' 'KFA' 'KFC' 'KAT' 'KAZ' 'RED' 'KHC' 'KHK' 'KGN' 'KHM'\n",
      " 'KHO' 'KDH' 'KEH' 'KAD' 'KBG' nan 'KGC' 'KHF' 'KFK' 'KHN' 'KAB' 'KAG'\n",
      " 'KAA' 'KGX' 'KAR' 'KAK' 'KBZ' '007' 'KBO' 'KCB' '013' 'KAY' 'KBE' 'KAS'\n",
      " 'KCL' '004' 'KAF' 'KCC' 'KEY' 'KDT' 'KAQ' 'KAH' 'KAM' 'KAJ' 'KFD' 'KCH'\n",
      " 'KFS' 'KAW' 'KAE' 'KBH' 'KDR' 'KHQ' 'KBW' 'KBY' 'KCI' 'KEJ' 'KFF' 'KBU'\n",
      " 'KAI' 'KCK' 'KDA' 'KES' 'KHP' 'KFL' 'KDS' 'KFP' 'KHS']\n",
      "Unique values in segment: ['02 - PARTICULARES' '03 - UNIVERSITARIO' '01 - TOP' nan]\n"
     ]
    }
   ],
   "source": [
    "for col in columnas_categoricas:\n",
    "    unique_values = df_comercial_activity[col].unique()\n",
    "    print(f\"Unique values in {col}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir columnas tipo object a tipo datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comercial_activity['pk_partition'] = pd.to_datetime(df_comercial_activity['pk_partition'], errors='coerce', format='%Y-%m-%d')\n",
    "df_comercial_activity['entry_date'] = pd.to_datetime(df_comercial_activity['entry_date'], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "df_socialdemographic['pk_partition'] = pd.to_datetime(df_socialdemographic['pk_partition'], errors='coerce', format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products['pk_partition'] = pd.to_datetime(df_products['pk_partition'], errors='coerce', format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA df_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5962924 entries, 0 to 5962923\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   Unnamed: 0          int64         \n",
      " 1   pk_cid              int64         \n",
      " 2   pk_partition        datetime64[ns]\n",
      " 3   short_term_deposit  int64         \n",
      " 4   loans               int64         \n",
      " 5   mortgage            int64         \n",
      " 6   funds               int64         \n",
      " 7   securities          int64         \n",
      " 8   long_term_deposit   int64         \n",
      " 9   em_account_pp       int64         \n",
      " 10  credit_card         int64         \n",
      " 11  payroll             float64       \n",
      " 12  pension_plan        float64       \n",
      " 13  payroll_account     int64         \n",
      " 14  emc_account         int64         \n",
      " 15  debit_card          int64         \n",
      " 16  em_account_p        int64         \n",
      " 17  em_acount           int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(15)\n",
      "memory usage: 818.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "      <th>short_term_deposit</th>\n",
       "      <th>loans</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>funds</th>\n",
       "      <th>securities</th>\n",
       "      <th>long_term_deposit</th>\n",
       "      <th>em_account_pp</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>payroll</th>\n",
       "      <th>pension_plan</th>\n",
       "      <th>payroll_account</th>\n",
       "      <th>emc_account</th>\n",
       "      <th>debit_card</th>\n",
       "      <th>em_account_p</th>\n",
       "      <th>em_acount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1375586</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1050611</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1050612</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1050613</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1050614</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   pk_cid pk_partition  short_term_deposit  loans  mortgage  \\\n",
       "0           0  1375586   2018-01-28                   0      0         0   \n",
       "1           1  1050611   2018-01-28                   0      0         0   \n",
       "2           2  1050612   2018-01-28                   0      0         0   \n",
       "3           3  1050613   2018-01-28                   1      0         0   \n",
       "4           4  1050614   2018-01-28                   0      0         0   \n",
       "\n",
       "   funds  securities  long_term_deposit  em_account_pp  credit_card  payroll  \\\n",
       "0      0           0                  0              0            0      0.0   \n",
       "1      0           0                  0              0            0      0.0   \n",
       "2      0           0                  0              0            0      0.0   \n",
       "3      0           0                  0              0            0      0.0   \n",
       "4      0           0                  0              0            0      0.0   \n",
       "\n",
       "   pension_plan  payroll_account  emc_account  debit_card  em_account_p  \\\n",
       "0           0.0                0            0           0             0   \n",
       "1           0.0                0            0           0             0   \n",
       "2           0.0                0            0           0             0   \n",
       "3           0.0                0            0           0             0   \n",
       "4           0.0                0            0           0             0   \n",
       "\n",
       "   em_acount  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_categoricas_1 = df_products.select_dtypes(include=['object']).columns.tolist()\n",
    "columnas_numericas_1 = df_products.select_dtypes(include=['int', 'float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columnas_categoricas_1:\n",
    "    unique_values = df_products[col].unique()\n",
    "    print(f\"Unique values in {col}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in columnas_numericas_1:\n",
    " #   unique_values = df_products[col].unique()\n",
    "  #  print(f\"Unique values in {col}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir columnas tipo object a tipo datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'pk_partition' a tipo datetime\n",
    "df_products['pk_partition'] = pd.to_datetime(df_products['pk_partition'])\n",
    "\n",
    "# Extraer solo la parte de la fecha (sin la hora)\n",
    "df_products['pk_partition'] = df_products['pk_partition'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2018, 1, 28), datetime.date(2018, 2, 28),\n",
       "       datetime.date(2018, 3, 28), datetime.date(2018, 4, 28),\n",
       "       datetime.date(2018, 5, 28), datetime.date(2018, 6, 28),\n",
       "       datetime.date(2018, 7, 28), datetime.date(2018, 8, 28),\n",
       "       datetime.date(2018, 9, 28), datetime.date(2018, 10, 28),\n",
       "       datetime.date(2018, 11, 28), datetime.date(2018, 12, 28),\n",
       "       datetime.date(2019, 1, 28), datetime.date(2019, 2, 28),\n",
       "       datetime.date(2019, 3, 28), datetime.date(2019, 4, 28),\n",
       "       datetime.date(2019, 5, 28)], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products['pk_partition'].unique()\n",
    "#Vemos que se han hecho los cambios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA df_socialdemographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5962924 entries, 0 to 5962923\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   Unnamed: 0    int64         \n",
      " 1   pk_cid        int64         \n",
      " 2   pk_partition  datetime64[ns]\n",
      " 3   country_id    object        \n",
      " 4   region_code   float64       \n",
      " 5   gender        object        \n",
      " 6   age           int64         \n",
      " 7   deceased      object        \n",
      " 8   salary        float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(3), object(3)\n",
      "memory usage: 409.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_socialdemographic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "      <th>country_id</th>\n",
       "      <th>region_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>deceased</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1375586</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>29.0</td>\n",
       "      <td>H</td>\n",
       "      <td>35</td>\n",
       "      <td>N</td>\n",
       "      <td>87218.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1050611</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>13.0</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>N</td>\n",
       "      <td>35548.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1050612</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>13.0</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>N</td>\n",
       "      <td>122179.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1050613</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>N</td>\n",
       "      <td>119775.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1050614</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>50.0</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   pk_cid pk_partition country_id  region_code gender  age  \\\n",
       "0           0  1375586   2018-01-28         ES         29.0      H   35   \n",
       "1           1  1050611   2018-01-28         ES         13.0      V   23   \n",
       "2           2  1050612   2018-01-28         ES         13.0      V   23   \n",
       "3           3  1050613   2018-01-28         ES         50.0      H   22   \n",
       "4           4  1050614   2018-01-28         ES         50.0      V   23   \n",
       "\n",
       "  deceased     salary  \n",
       "0        N   87218.10  \n",
       "1        N   35548.74  \n",
       "2        N  122179.11  \n",
       "3        N  119775.54  \n",
       "4        N        NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_socialdemographic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_categoricas_2 = df_socialdemographic.select_dtypes(include=['object']).columns.tolist()\n",
    "columnas_numericas_2 = df_socialdemographic.select_dtypes(include=['int', 'float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in country_id: ['ES' 'CA' 'CH' 'CL' 'IE' 'AT' 'FR' 'GB' 'DE' 'DO' 'BE' 'AR' 'VE' 'US'\n",
      " 'MX' 'PL' 'MA' 'GT' 'GA' 'CO' 'BR' 'RU' 'IT' 'NO' 'SN' 'MR' 'ET' 'CN'\n",
      " 'CM' 'SA' 'CI' 'QA' 'LU' 'SE' 'DJ' 'PT' 'JM' 'RO' 'HU' 'DZ' 'PE']\n",
      "Unique values in gender: ['H' 'V' nan]\n",
      "Unique values in deceased: ['N' 'S']\n"
     ]
    }
   ],
   "source": [
    "for col in columnas_categoricas_2:\n",
    "    unique_values = df_socialdemographic[col].unique()\n",
    "    print(f\"Unique values in {col}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in columnas_numericas_2:\n",
    " #   unique_values = df_socialdemographic[col].unique()\n",
    "  #  print(f\"Unique values in {col}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir columnas tipo object en tipo datatime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'pk_partition' a tipo datetime\n",
    "df_socialdemographic['pk_partition'] = pd.to_datetime(df_socialdemographic['pk_partition'])\n",
    "\n",
    "# Extraer solo la parte de la fecha (sin la hora)\n",
    "df_socialdemographic['pk_partition'] = df_socialdemographic['pk_partition'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socialdemographic['pk_partition'].unique()\n",
    "#Vemos que se han hecho los cambios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Univariable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis Univariable df_comercial_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero vamos a hacer los histogramas de las variables numéricas.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seleccionar solo las columnas numéricas\n",
    "numeric_columns = df_comercial_activity.select_dtypes(include=[int, float]).columns\n",
    "\n",
    "# Crear gráficos individuales\n",
    "for col in numeric_columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df_comercial_activity[col].hist(bins=50)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora crearemos histogramas para todas las columnas categóricas\n",
    "categorical_columns = df_comercial_activity.select_dtypes(include=[object, 'bool'])\n",
    "for column in categorical_columns:\n",
    "    df_comercial_activity[column].value_counts().plot(kind='bar', title=column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis Univariable df_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero vamos a hacer los histogramas de las variables numéricas.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seleccionar solo las columnas numéricas\n",
    "numeric_columns_1 = df_products.select_dtypes(include=[int, float]).columns\n",
    "\n",
    "# Crear gráficos individuales\n",
    "for col in numeric_columns_1:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df_products[col].hist(bins=50)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora crearemos histogramas para todas las columnas categóricas\n",
    "categorical_columns_1 = df_products.select_dtypes(include=[object, 'bool'])\n",
    "for column in categorical_columns:\n",
    "    df_products[column].value_counts().plot(kind='bar', title=column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis Univariable df_socialdemographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero vamos a hacer los histogramas de las variables numéricas.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seleccionar solo las columnas numéricas\n",
    "numeric_columns_2 = df_socialdemographic.select_dtypes(include=[int, float]).columns\n",
    "\n",
    "# Crear gráficos individuales\n",
    "for col in numeric_columns_2:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df_socialdemographic[col].hist(bins=50)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora crearemos histogramas para todas las columnas categóricas\n",
    "categorical_columns_2 = df_socialdemographic.select_dtypes(include=[object, 'bool'])\n",
    "for column in categorical_columns_2:\n",
    "    df_socialdemographic[column].value_counts().plot(kind='bar', title=column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_channel</th>\n",
       "      <th>active_customer</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, pk_cid, pk_partition, entry_date, entry_channel, active_customer, segment]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comercial_activity[df_comercial_activity.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "      <th>short_term_deposit</th>\n",
       "      <th>loans</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>funds</th>\n",
       "      <th>securities</th>\n",
       "      <th>long_term_deposit</th>\n",
       "      <th>em_account_pp</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>payroll</th>\n",
       "      <th>pension_plan</th>\n",
       "      <th>payroll_account</th>\n",
       "      <th>emc_account</th>\n",
       "      <th>debit_card</th>\n",
       "      <th>em_account_p</th>\n",
       "      <th>em_acount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, pk_cid, pk_partition, short_term_deposit, loans, mortgage, funds, securities, long_term_deposit, em_account_pp, credit_card, payroll, pension_plan, payroll_account, emc_account, debit_card, em_account_p, em_acount]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products[df_products.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "      <th>country_id</th>\n",
       "      <th>region_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>deceased</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, pk_cid, pk_partition, country_id, region_code, gender, age, deceased, salary]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_socialdemographic[df_socialdemographic.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NULOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulos df_comercial_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              0\n",
       "pk_cid                  0\n",
       "pk_partition            0\n",
       "entry_date           6413\n",
       "entry_channel      133033\n",
       "active_customer         0\n",
       "segment            133944\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos los nulos que hay en cada columna\n",
    "df_comercial_activity.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como previamente hemos hecho una visualización de las columnas y sus variables ya tenemos una idea clara de las acciones que vamos a realizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna Unnamed\n",
    "\n",
    "df_comercial_activity.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nulos columna \"entry_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comercial_activity = df_comercial_activity.dropna(subset=['entry_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nulos columna \"entry_channel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entry_channel\n",
       "KHE    5.346357e-01\n",
       "KFC    1.527951e-01\n",
       "KHQ    1.013456e-01\n",
       "KAT    7.140100e-02\n",
       "KHK    3.952010e-02\n",
       "           ...     \n",
       "KES    1.888597e-06\n",
       "KEJ    1.373525e-06\n",
       "KHS    8.584534e-07\n",
       "KDA    3.433814e-07\n",
       "KFP    3.433814e-07\n",
       "Name: proportion, Length: 67, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comercial_activity['entry_channel'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "entry_channel\n",
      "KHE    5.346363e-01\n",
      "KFC    1.527955e-01\n",
      "KHQ    1.013457e-01\n",
      "KAT    7.140103e-02\n",
      "KHK    3.952028e-02\n",
      "           ...     \n",
      "KBY    1.846719e-06\n",
      "KEJ    1.343068e-06\n",
      "KHS    8.394176e-07\n",
      "KDA    3.357670e-07\n",
      "KFP    3.357670e-07\n",
      "Name: proportion, Length: 67, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Vamos a imputar los nulos en base al porcentaje que ocupan sobre el total sus variables.\n",
    "\n",
    "\n",
    "# Calcular el porcentaje de cada categoría en entry_channel\n",
    "porcentajes = df_comercial_activity['entry_channel'].value_counts(normalize=True)\n",
    "\n",
    "# Número de nulos en la columna entry_channel\n",
    "nulos_count = df_comercial_activity['entry_channel'].isnull().sum()\n",
    "\n",
    "# Crear una lista para almacenar las categorías de acuerdo al porcentaje\n",
    "nulos_relleno = []\n",
    "\n",
    "for categoria, porcentaje in porcentajes.items():\n",
    "    count_categoria = int(round(porcentaje * nulos_count))\n",
    "    nulos_relleno.extend([categoria] * count_categoria)\n",
    "\n",
    "# Ajustar la lista en caso de diferencias debido a redondeos\n",
    "if len(nulos_relleno) < nulos_count:\n",
    "    diferencia = nulos_count - len(nulos_relleno)\n",
    "    nulos_relleno.extend(np.random.choice(porcentajes.index, diferencia, p=porcentajes.values))\n",
    "elif len(nulos_relleno) > nulos_count:\n",
    "    nulos_relleno = nulos_relleno[:nulos_count]\n",
    "\n",
    "# Barajar la lista de relleno para distribuir aleatoriamente los valores\n",
    "np.random.shuffle(nulos_relleno)\n",
    "\n",
    "# Rellenar los nulos en la columna entry_channel\n",
    "df_comercial_activity.loc[df_comercial_activity['entry_channel'].isnull(), 'entry_channel'] = nulos_relleno\n",
    "\n",
    "# Verificar el resultado\n",
    "print(df_comercial_activity['entry_channel'].isnull().sum())\n",
    "print(df_comercial_activity['entry_channel'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry_channel\n",
      "KHE      0.534636\n",
      "KFC      0.152795\n",
      "KHQ      0.101346\n",
      "KAT      0.071401\n",
      "Otros    0.070508\n",
      "KHK      0.039520\n",
      "KHM      0.029793\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Una vez imputados los nulos agrupamos todas quellas variables que representan muy poco porcentaje sobre el total, de esta forma reducimos variables.\n",
    "#Vamos a agrupar todas aquellas variables que representen el 2% o menos\n",
    "# Calcular el porcentaje de cada categoría en entry_channel\n",
    "porcentajes = df_comercial_activity['entry_channel'].value_counts(normalize=True)\n",
    "\n",
    "# Identificar las categorías con porcentaje menor o igual al 2%\n",
    "categorias_bajas = porcentajes[porcentajes <= 0.02].index\n",
    "\n",
    "# Reemplazar las categorías de bajo porcentaje con \"Otros\"\n",
    "df_comercial_activity['entry_channel'] = df_comercial_activity['entry_channel'].replace(categorias_bajas, 'Otros')\n",
    "\n",
    "# Verificar el resultado\n",
    "print(df_comercial_activity['entry_channel'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nulos columna \"segment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputaremos los nulos con la palabra \"Unknown\"\n",
    "df_comercial_activity['segment'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comercial_activity.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulos df_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             0\n",
       "pk_cid                 0\n",
       "pk_partition           0\n",
       "short_term_deposit     0\n",
       "loans                  0\n",
       "mortgage               0\n",
       "funds                  0\n",
       "securities             0\n",
       "long_term_deposit      0\n",
       "em_account_pp          0\n",
       "credit_card            0\n",
       "payroll               61\n",
       "pension_plan          61\n",
       "payroll_account        0\n",
       "emc_account            0\n",
       "debit_card             0\n",
       "em_account_p           0\n",
       "em_acount              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna Unnamed\n",
    "\n",
    "df_products.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En esta base de datos la cantidad de nulos no es significativa así que los vamos a eliminar.\n",
    "df_products = df_products.dropna(subset=['payroll', 'pension_plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products[\"em_account_pp\"].unique()\n",
    "#Vemos que en la columna em_account_pp solo hay una variable (0). Esa columna no aporta nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.drop(columns=['em_account_pp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulos df_socialdemographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "pk_cid                0\n",
       "pk_partition          0\n",
       "country_id            0\n",
       "region_code        2264\n",
       "gender               25\n",
       "age                   0\n",
       "deceased              0\n",
       "salary          1512103\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_socialdemographic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna Unnamed\n",
    "\n",
    "df_socialdemographic.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_id\n",
      "ES       5960672\n",
      "Otros       2252\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Primero vamos a agrupar todas las variables menos (ES) de la columna \"country_id\" en una sola variable llamada Otros\n",
    "# Agrupar todas las variables menos 'ES' en 'Otros' para la columna 'country_id'\n",
    "df_socialdemographic['country_id'] = df_socialdemographic['country_id'].apply(lambda x: x if x == 'ES' else 'Otros')\n",
    "\n",
    "# Verificar el resultado\n",
    "print(df_socialdemographic['country_id'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "18-25     2935117\n",
      "26-35     1545217\n",
      "36-45      744912\n",
      "46-65      571455\n",
      "66-110     132261\n",
      "0-17        33962\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Ahora vamos a agrupar las cariables de la columna \"age\" en varios grupos de edades\n",
    "\n",
    "# Definir los límites de los grupos de edad\n",
    "bins = [0, 17, 25, 35, 45, 65, 110]\n",
    "\n",
    "# Definir los nombres de los grupos de edad\n",
    "labels = ['0-17', '18-25', '26-35', '36-45', '46-65', '66-110']\n",
    "\n",
    "#Poner títulos a los rangos de edad (falta código Ivan)\n",
    "\n",
    "# Agrupar las edades en los intervalos especificados\n",
    "df_socialdemographic['age'] = pd.cut(df_socialdemographic['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(df_socialdemographic['age'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En esta base de datos hay columnas con pocos nulos así que los vamos a eliminar\n",
    "df_socialdemographic = df_socialdemographic.dropna(subset=['region_code', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socialdemographic.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordenar dataframe por fecha de mas atigua a mas nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "      <th>country_id</th>\n",
       "      <th>region_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>deceased</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1375586</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>29.0</td>\n",
       "      <td>H</td>\n",
       "      <td>36-45</td>\n",
       "      <td>N</td>\n",
       "      <td>87218.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159590</th>\n",
       "      <td>1329749</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>18-25</td>\n",
       "      <td>N</td>\n",
       "      <td>80471.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159591</th>\n",
       "      <td>1329751</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>9.0</td>\n",
       "      <td>H</td>\n",
       "      <td>18-25</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159592</th>\n",
       "      <td>1329752</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>33.0</td>\n",
       "      <td>H</td>\n",
       "      <td>18-25</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159593</th>\n",
       "      <td>1329753</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>18-25</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665407</th>\n",
       "      <td>1489298</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>30.0</td>\n",
       "      <td>V</td>\n",
       "      <td>36-45</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665406</th>\n",
       "      <td>1489299</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>30.0</td>\n",
       "      <td>H</td>\n",
       "      <td>46-65</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665405</th>\n",
       "      <td>1489268</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>28.0</td>\n",
       "      <td>H</td>\n",
       "      <td>26-35</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665416</th>\n",
       "      <td>1489286</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>3.0</td>\n",
       "      <td>H</td>\n",
       "      <td>36-45</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960634</th>\n",
       "      <td>1550586</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>28.0</td>\n",
       "      <td>H</td>\n",
       "      <td>36-45</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5960635 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pk_cid pk_partition country_id  region_code gender    age deceased  \\\n",
       "0        1375586   2018-01-28         ES         29.0      H  36-45        N   \n",
       "159590   1329749   2018-01-28         ES         50.0      H  18-25        N   \n",
       "159591   1329751   2018-01-28         ES          9.0      H  18-25        N   \n",
       "159592   1329752   2018-01-28         ES         33.0      H  18-25        N   \n",
       "159593   1329753   2018-01-28         ES          1.0      H  18-25        N   \n",
       "...          ...          ...        ...          ...    ...    ...      ...   \n",
       "5665407  1489298   2019-05-28         ES         30.0      V  36-45        N   \n",
       "5665406  1489299   2019-05-28         ES         30.0      H  46-65        N   \n",
       "5665405  1489268   2019-05-28         ES         28.0      H  26-35        N   \n",
       "5665416  1489286   2019-05-28         ES          3.0      H  36-45        N   \n",
       "5960634  1550586   2019-05-28         ES         28.0      H  36-45        N   \n",
       "\n",
       "          salary  \n",
       "0        87218.1  \n",
       "159590   80471.1  \n",
       "159591       NaN  \n",
       "159592       NaN  \n",
       "159593       NaN  \n",
       "...          ...  \n",
       "5665407      NaN  \n",
       "5665406      NaN  \n",
       "5665405      NaN  \n",
       "5665416      NaN  \n",
       "5960634      NaN  \n",
       "\n",
       "[5960635 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenar el DataFrame por la columna 'pk_partition' de más antiguo a más nuevo\n",
    "df_socialdemographic = df_socialdemographic.sort_values(by='pk_partition', ascending=True)\n",
    "df_socialdemographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2018, 1, 28), datetime.date(2018, 2, 28),\n",
       "       datetime.date(2018, 3, 28), datetime.date(2018, 4, 28),\n",
       "       datetime.date(2018, 5, 28), datetime.date(2018, 6, 28),\n",
       "       datetime.date(2018, 7, 28), datetime.date(2018, 8, 28),\n",
       "       datetime.date(2018, 9, 28), datetime.date(2018, 10, 28),\n",
       "       datetime.date(2018, 11, 28), datetime.date(2018, 12, 28),\n",
       "       datetime.date(2019, 1, 28), datetime.date(2019, 2, 28),\n",
       "       datetime.date(2019, 3, 28), datetime.date(2019, 4, 28),\n",
       "       datetime.date(2019, 5, 28)], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_socialdemographic[\"pk_partition\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quedarnos con las fechas más recientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VEMOS QUE HAY CLIENTES QUE ESTÁN REPETIDOS, NOS QUEDAMOS CON SU INFORMACIÓN MAS RCIENTE, ES DECIR, QUE NOS QUEDAMOS CON UN SOLA \"FILA\" POR CLIENTE  (LA QUE TENGA LA FECHA MÁS RECIENTE, ESO EN TODOS LOD DF Y LUEGO INTENTAMOS HACER UN MERGE, PRIMERO CON \"PK_CID\" Y LUEGO JUNTAMOS LOS 2 DF QUE QUEDAN A APRTIR DE LA COLUMNA \"PK_PARTITION\" PORQUE SE SUPONE QUE TENEMOS LAS MISMAS FECHAS EN AMBOS DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que para unir df_comercial_activity y df_socialdemographic solo se puede hacer a través de la columna \"pk_cid\", por lo tanto, lo primero que hay que hacer es quedarnos con la info de cada cliente pero sin que esté repetida, nos quedamos con la información con fecha más reciente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pk_cid\n",
       "1375586    17\n",
       "1328873    17\n",
       "1328875    17\n",
       "1328876    17\n",
       "1328877    17\n",
       "           ..\n",
       "1523351     1\n",
       "269752      1\n",
       "1523348     1\n",
       "1523346     1\n",
       "1550586     1\n",
       "Name: count, Length: 454899, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comercial_activity[\"pk_cid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pk_cid\n",
       "1375586    17\n",
       "1056661    17\n",
       "1056645    17\n",
       "1056646    17\n",
       "1056647    17\n",
       "           ..\n",
       "1528381     1\n",
       "1527625     1\n",
       "1527606     1\n",
       "1527611     1\n",
       "1550586     1\n",
       "Name: count, Length: 456225, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_socialdemographic[\"pk_cid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quedarse con la transacción más reciente por usuario (pk_cid)\n",
    "df_comercial_activity_recent = df_comercial_activity.sort_values('pk_partition').groupby('pk_cid').tail(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pk_cid\n",
       "1298102    1\n",
       "324846     1\n",
       "336162     1\n",
       "337281     1\n",
       "336874     1\n",
       "          ..\n",
       "1156210    1\n",
       "1156209    1\n",
       "1156208    1\n",
       "1156207    1\n",
       "1550586    1\n",
       "Name: count, Length: 454899, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comercial_activity_recent[\"pk_cid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = df_comercial_activity_recent[['pk_cid', 'pk_partition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1298102</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1297423</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1299811</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1299907</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1299380</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454894</th>\n",
       "      <td>1490987</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454895</th>\n",
       "      <td>1490988</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454896</th>\n",
       "      <td>1490991</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454897</th>\n",
       "      <td>1490992</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454898</th>\n",
       "      <td>1550586</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454899 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pk_cid pk_partition\n",
       "0       1298102   2018-07-28\n",
       "1       1297423   2018-07-28\n",
       "2       1299811   2018-07-28\n",
       "3       1299907   2018-07-28\n",
       "4       1299380   2018-07-28\n",
       "...         ...          ...\n",
       "454894  1490987   2019-05-28\n",
       "454895  1490988   2019-05-28\n",
       "454896  1490991   2019-05-28\n",
       "454897  1490992   2019-05-28\n",
       "454898  1550586   2019-05-28\n",
       "\n",
       "[454899 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quedarse con la transacción más reciente por usuario (pk_cid)\n",
    "df_socialdemographic_recent = df_socialdemographic.sort_values('pk_partition').groupby('pk_cid').tail(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nos hemos dado cuenta de que el type de la columna \"plk_partition\" era object y lo estamos cambiando a datetime\n",
    "df_socialdemographic_recent['pk_partition'] = pd.to_datetime(df_socialdemographic_recent['pk_partition'], errors='coerce', format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 456225 entries, 0 to 456224\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   pk_cid        456225 non-null  int64         \n",
      " 1   pk_partition  456225 non-null  datetime64[ns]\n",
      " 2   country_id    456225 non-null  object        \n",
      " 3   region_code   456225 non-null  float64       \n",
      " 4   gender        456225 non-null  object        \n",
      " 5   age           456225 non-null  category      \n",
      " 6   deceased      456225 non-null  object        \n",
      " 7   salary        299441 non-null  float64       \n",
      "dtypes: category(1), datetime64[ns](1), float64(2), int64(1), object(3)\n",
      "memory usage: 24.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_socialdemographic_recent.info()\n",
    "#Vemos que ya se ha hecho el cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pk_cid\n",
       "635756     1\n",
       "1095396    1\n",
       "1095383    1\n",
       "1095384    1\n",
       "1095385    1\n",
       "          ..\n",
       "1487030    1\n",
       "1487062    1\n",
       "1487035    1\n",
       "1487034    1\n",
       "1550586    1\n",
       "Name: count, Length: 456225, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_socialdemographic_recent[\"pk_cid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1298102</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1297423</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1299811</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1299907</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1299380</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454894</th>\n",
       "      <td>1490987</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454895</th>\n",
       "      <td>1490988</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454896</th>\n",
       "      <td>1490991</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454897</th>\n",
       "      <td>1490992</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454898</th>\n",
       "      <td>1550586</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454899 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pk_cid pk_partition\n",
       "0       1298102   2018-07-28\n",
       "1       1297423   2018-07-28\n",
       "2       1299811   2018-07-28\n",
       "3       1299907   2018-07-28\n",
       "4       1299380   2018-07-28\n",
       "...         ...          ...\n",
       "454894  1490987   2019-05-28\n",
       "454895  1490988   2019-05-28\n",
       "454896  1490991   2019-05-28\n",
       "454897  1490992   2019-05-28\n",
       "454898  1550586   2019-05-28\n",
       "\n",
       "[454899 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison_1 = df_comercial_activity_recent[['pk_cid', 'pk_partition']]\n",
    "df_comparison_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pk_cid\n",
       "1375586    17\n",
       "1328802    17\n",
       "1328781    17\n",
       "1328782    17\n",
       "1328783    17\n",
       "           ..\n",
       "1521045     1\n",
       "1545224     1\n",
       "1470941     1\n",
       "1521049     1\n",
       "1550586     1\n",
       "Name: count, Length: 456373, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products[\"pk_cid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quedarse con la transacción más reciente por usuario (pk_cid)\n",
    "df_products = df_products.sort_values('pk_partition').groupby('pk_cid').tail(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pk_cid\n",
       "1298102    1\n",
       "327107     1\n",
       "313869     1\n",
       "313778     1\n",
       "336682     1\n",
       "          ..\n",
       "1156347    1\n",
       "1156346    1\n",
       "1156345    1\n",
       "1156344    1\n",
       "1550586    1\n",
       "Name: count, Length: 456373, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products[\"pk_cid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_cid</th>\n",
       "      <th>pk_partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1298102</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1297423</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1299907</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1299811</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1299380</td>\n",
       "      <td>2018-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456368</th>\n",
       "      <td>1489285</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456369</th>\n",
       "      <td>1489286</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456370</th>\n",
       "      <td>1489287</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456371</th>\n",
       "      <td>1489273</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456372</th>\n",
       "      <td>1550586</td>\n",
       "      <td>2019-05-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456373 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pk_cid pk_partition\n",
       "0       1298102   2018-07-28\n",
       "1       1297423   2018-07-28\n",
       "2       1299907   2018-07-28\n",
       "3       1299811   2018-07-28\n",
       "4       1299380   2018-07-28\n",
       "...         ...          ...\n",
       "456368  1489285   2019-05-28\n",
       "456369  1489286   2019-05-28\n",
       "456370  1489287   2019-05-28\n",
       "456371  1489273   2019-05-28\n",
       "456372  1550586   2019-05-28\n",
       "\n",
       "[456373 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison_2 = df_products[['pk_cid', 'pk_partition']]\n",
    "df_comparison_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de seguir haciendo limpieza hay que hacer un Join de los 3 deaframes (joinfechafresca.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join Nico\n",
    "#df_final = pd.merge(df_comercial_activity_recent, df_socialdemographic_recent, on = \"pk_cid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionar df_comercial_activity y df_products por 'pk_cid' \n",
    "df_merged = pd.merge(df_comercial_activity, df_products, on='pk_cid', how='inner', suffixes=('_comercial', '_product'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5956511 entries, 0 to 5956510\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   pk_cid              int64         \n",
      " 1   pk_partition        datetime64[ns]\n",
      " 2   entry_date          datetime64[ns]\n",
      " 3   entry_channel       object        \n",
      " 4   active_customer     float64       \n",
      " 5   segment             object        \n",
      " 6   short_term_deposit  int64         \n",
      " 7   loans               int64         \n",
      " 8   mortgage            int64         \n",
      " 9   funds               int64         \n",
      " 10  securities          int64         \n",
      " 11  long_term_deposit   int64         \n",
      " 12  credit_card         int64         \n",
      " 13  payroll             float64       \n",
      " 14  pension_plan        float64       \n",
      " 15  payroll_account     int64         \n",
      " 16  emc_account         int64         \n",
      " 17  debit_card          int64         \n",
      " 18  em_account_p        int64         \n",
      " 19  em_acount           int64         \n",
      "dtypes: datetime64[ns](2), float64(3), int64(13), object(2)\n",
      "memory usage: 908.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a borrar la columna \"pk_partition_product\" porque está duplicada y a parte es type object\n",
    "df_merged.drop(columns=['pk_partition_product'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.rename(columns={'pk_partition_comercial': 'pk_partition'})\n",
    "#Cambiamos el nombre de la columna para dejar el nombre estandar de antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 668. MiB for an array with shape (87588718,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fusionar el resultado con df_socialdemographic por 'pk_cid'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_final \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_merged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_socialdemographic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpk_cid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_merged\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_social\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Herre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Herre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:886\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mc:\\Users\\Herre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1151\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1148\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1151\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Herre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1125\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Herre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1759\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[0;32m   1757\u001b[0m     _, lidx, ridx \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mjoin(right, how\u001b[38;5;241m=\u001b[39mhow, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1759\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mget_join_indexers_non_unique\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(lidx, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m   1764\u001b[0m     lidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Herre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1799\u001b[0m, in \u001b[0;36mget_join_indexers_non_unique\u001b[1;34m(left, right, sort, how)\u001b[0m\n\u001b[0;32m   1797\u001b[0m     ridx, lidx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mleft_outer_join(rkey, lkey, count, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1798\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1799\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mlibjoin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1801\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mfull_outer_join(lkey, rkey, count)\n",
      "File \u001b[1;32mjoin.pyx:48\u001b[0m, in \u001b[0;36mpandas._libs.join.inner_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 668. MiB for an array with shape (87588718,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Fusionar el resultado con df_socialdemographic por 'pk_cid'\n",
    "df_final = pd.merge(df_merged, df_socialdemographic, on='pk_cid', how='inner', suffixes=('_merged', '_social'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
